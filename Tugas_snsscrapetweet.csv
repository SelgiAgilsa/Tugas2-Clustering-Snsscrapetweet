""
""
"Klastering data twitter menggunakan keyword ""narkoba"" Start= 2022–09–15"
"End = 2022–10–15"
""
"!pip3 install snscrape"
""
"pip install langdetect"
""
"import snscrape.modules.twitter as sntwitter"
"import json"
"from langdetect import detect"
""
"keywords=['narkoba']"
"start=""2022–09–15"""
"end =""2022–10–15"""
"max_num=10"
"fname='tweet.json'"
"languages=['id','en']"
""
"import pandas as pd"
"datatwitter=[]"
""
"for keyword in keywords:"
""
"for i, tweet in enumerate (sntwitter.TwitterSearchScraper(f'{keyword} ').get_items()):"
""
"try:"
"lan=detect(tweet.content)"
"except:"
"lan='error'"
"if i == max_num:"
"break"
"if lan in languages:"
"data = {'id': tweet.id, 'username':tweet.username, 'date': tweet.date, 'text': tweet.content,'url':tweet.url}"
"# print(data)"
"datatwitter.append(tweet.content)"
"with open(fname, 'a+', encoding='utf-8') as f:"
"line = json.dumps(data, ensure_ascii=False,default=str)"
"#print(line)"
"f.write(line)"
"f.write('\n')"
""
"datatwitter"
""
"['Viral Lagi Freddy Budiman, Gembong Narkoba yang Dieksekusi Mati, Ngaku Setor Rp 90 M ke Polri\nhttps://t.co/CuJKTsGmUH',"
"'@dr_tompi Tp beliau ditangkap krn jaringan narkoba yg dikendalikannya bkn krn pemakai, si andi arief demokrat jg pernah ketangkep make cm kena rehab aja',"
"'@alisyarief Geng Narkoba vs Geng Judi',"
"'Jenderal Dagang Narkoba: Catatan atas Delapan Tahun Revolusi Mental Jokowi https://t.co/RD6GwPuXWZ',"
"'@siapkawalpolri @ListyoSigitP Kalo ada polri yang nyalahgunain narkoba kek si Teddy sih wajib banget diberhentikan secara tidak terhormat &amp; dihukum penjara seumur hidup gak sih pak @ListyoSigitP?',"
"'Buntut dari penyalahgunaan peredaran narkoba, Polda Metro Jaya pecat lima anggota.\nhttps://t.co/AjnhqW81Wm https://t.co/pmo9HMlRNO',"
"'jadi pengendali penjualan narkoba keren juga Irjen tm, pantesan kaya',"
"'Dukungan Tokoh Masyarakat dan Tokoh Agama kepada Polrestabes Medan untuk memberantas Judi, Narkoba dan penyakit masyarakat lainnya. https://t.co/CnpCGABmfv',"
"'mana mungkin sanggup urusi hankian teroris dan anakmya\nrampok\ntak uang rampok narkoba\nsampai q tina hajar https://t.co/maYLhMqg8i',"
"'@detikcom Yg kek gini hrs di hukum mati krn memperkaya diri dengan merusak generasi muda... gembar gembor berantas narkoba setelah dpt pujian narkoba nya dijual ini lebih jahat dari pengedar nya @DivHumas_Polri']"
""
"!pip install Sastrawi"
""
"import re"
"import string"
"from Sastrawi.Stemmer.StemmerFactory import StemmerFactory# create stemmer"
"factory = StemmerFactory()"
"stemmer = factory.create_stemmer()# stemming process"
"# import StopWordRemoverFactory class"
"from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
"factory = StopWordRemoverFactory()"
"stopword = factory.create_stop_word_remover()"
"documents_clean=[]"
""
"for d in datatwitter:"
"outputstem= stemmer.stem(d)"
"d= stopword.remove(outputstem)"
"# Remove Unicode"
"document_test = re.sub(r'[^\x00-\x7F]+', ' ', d)"
"# Remove Mentions"
"document_test = re.sub(r'@\w+', '', document_test)"
"# Lowercase the document"
"document_test = document_test.lower()"
"# Remove punctuations"
"document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)"
"# Lowercase the numbers"
"document_test = re.sub(r'[0-9]', '', document_test)"
"# Remove the doubled space"
"outputstop = re.sub(r'\s{2,}', ' ', document_test)"
"documents_clean.append(outputstop)"
""
"documents_clean[0:5]"
""
"['viral freddy budiman gembong narkoba eksekusi mati ngaku setor rp m polri https t co cujktsgmuh',"
"'dr tompi tp beliau tangkap krn jaring narkoba yg kendali bkn krn pakai si andi arief demokrat jg pernah ketangkep make cm kena rehab aja',"
"'alisyarief geng narkoba vs geng judi',"
"'jenderal dagang narkoba catat atas delapan tahun revolusi mental jokowi https t co rdgwpuxwz',"
"'siapkawalpolri listyosigitp kalo polri nyalahgunain narkoba kek si teddy sih wajib banget henti cara hormat amp hukum penjara umur hidup gak sih pak listyosigitp']"
""
"from sklearn.feature_extraction.text import TfidfVectorizer"
"import pandas as pd"
"tfidfvectorizer = TfidfVectorizer(analyzer='word')"
"tfidf_wm = tfidfvectorizer.fit_transform(documents_clean)"
"tfidf_tokens = tfidfvectorizer.get_feature_names()"
""
"from sklearn.feature_extraction.text import CountVectorizer"
"import matplotlib.pyplot as plt"
"import numpy as np # linear algebra"
"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
"cv = CountVectorizer()"
"words = cv.fit_transform(documents_clean)"
"sum_words = words.sum(axis=0)"
""
""
"words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]"
"words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)"
"frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])"
""
"color = plt.cm.twilight(np.linspace(0, 1, 20))"
"frequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 7), color = color)"
"plt.title(""Most Frequently Occuring Words - Top 20"")"
""
"Text(0.5, 1.0, 'Most Frequently Occuring Words - Top 20')"
""
"[]"
""
"from sklearn.cluster import KMeans"
"true_k = 3"
"model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)"
"model.fit(words)"
""
"order_centroids = model.cluster_centers_.argsort()[:, ::-1]"
"terms = cv.get_feature_names()"
""
"for i in range(true_k):"
"print(""Cluster %d:"" % i),"
"for ind in order_centroids[i, :10]:"
"print(' %s' % terms[ind]),"
"print"
""
"print(""\n"")"
""
"Cluster 0:"
"tokoh"
"masyarakat"
"agama"
"https"
"dukung"
"judi"
"polrestabes"
"narkoba"
"co"
"sakit"
"Cluster 1:"
"co"
"https"
"narkoba"
"lima"
"delapan"
"revolusi"
"dagang"
"mental"
"polda"
"catat"
"Cluster 2:"
"narkoba"
"polri"
"krn"
"sih"
"kek"
"kaya"
"listyosigitp"
"jual"
"mati"
"hukum"
""
"/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead."
"warnings.warn(msg, category=FutureWarning)"
""
"print(""Prediction"")"
"Y = cv.transform([""sabu""])"
"prediction = model.predict(Y)"
"print(""Cluster number :"", prediction)"
"Y = cv.transform([""polri""])"
"prediction = model.predict(Y)"
"print(""Cluster number :"", prediction)"
""
"Prediction"
"Cluster number : [2]"
"Cluster number : [2]"
""
"import scipy.cluster.hierarchy as sch"
"X = cv.fit_transform(documents_clean).todense()"
"dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward',metric='euclidean'),orientation=""top"")"
"plt.title('Dendrogram')"
"plt.xlabel('Jarak Ward')"
"plt.ylabel('Nomor Dokumen')"
"plt.show()"
""
"[]"
""
"import scipy.cluster.hierarchy as sch"
"X = cv.fit_transform(documents_clean).todense()"
"dendrogram = sch.dendrogram(sch.linkage(X, method = 'average',metric='euclidean'),orientation=""right"")"
"plt.title('Dendrogram')"
"plt.xlabel('Jarak Rerata')"
"plt.ylabel('Nomor Dokumen')"
"plt.show()"
""
"[]"
""
"from sklearn.cluster import AgglomerativeClustering"
""
"cluster = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')"
"cluster.fit_predict(X)"
"print(cluster.labels_)"
""
"[0 3 0 0 5 0 0 2 4 1]"
""
"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html"
"FutureWarning,"
""
"from scipy.cluster.hierarchy import dendrogram, linkage"
"from matplotlib import pyplot as plt"
""
"linked = linkage(X, 'single')"
""
"labelList = range(0, 10)"
""
"plt.figure(figsize=(10, 7))"
"dendrogram(linked,"
"orientation='top',"
"labels=labelList,"
"distance_sort='descending',"
"show_leaf_counts=True)"
"plt.show()"
""
"[]"
""
"from scipy.cluster.hierarchy import dendrogram, linkage"
"from matplotlib import pyplot as plt"
""
"linked = linkage(X, 'average')"
""
"labelList = range(0, 10)"
""
"plt.figure(figsize=(10, 7))"
"dendrogram(linked,"
"orientation='top',"
"labels=labelList,"
"distance_sort='descending',"
"show_leaf_counts=True)"
"plt.show()"
""
"[]"
